{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "import pickle\n",
    "from os import path\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "API = \"https://explorer.helium.foundation/api\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dashed(name):\n",
    "    ''' Convert title name to lower dashed name '''\n",
    "    return \"-\".join(name.lower().split(\" \"))\n",
    "\n",
    "def get_loc(hotspots, name):\n",
    "    ''' Get location of given hotspot name '''\n",
    "    return next(x for x in hotspots if dashed(x['name']) == name)['location']\n",
    "\n",
    "def get_witnesses(hname, b58):\n",
    "    ''' Get witnesses for given hotspot name and b58 addr '''\n",
    "    r = requests.get(\"{}/witnesses/{}\".format(API, b58))\n",
    "    assert(r.status_code == 200)\n",
    "    witnesses = r.json()['data']\n",
    "    if len(witnesses) > 0:\n",
    "        witnesses = [dashed(w['name']) for w in witnesses]\n",
    "    else:\n",
    "        witnesses = []\n",
    "    return {\"name\": dashed(hname), \"witnesses\": witnesses}\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    ''' Class to represent a graph node '''\n",
    "    loc: str\n",
    "    name: str\n",
    "\n",
    "    # to make this class hashable\n",
    "    def __eq__(self, other):\n",
    "        return self.loc == other.loc and self.name == other.name\n",
    "    def __hash__(self):\n",
    "        return int(self.loc, 16)\n",
    "\n",
    "def create_witness_dict(witness_list):\n",
    "    ''' Create witness dictionary from list of witnesses '''\n",
    "    witnesses = {}\n",
    "    for d in witness_list:\n",
    "        h = d['name']\n",
    "        ws = d['witnesses']\n",
    "        h_loc = get_loc(hotspots, h)\n",
    "        if h_loc:\n",
    "            key = Node(name=h, loc=h_loc)\n",
    "            if len(ws) > 0:\n",
    "                nodes = []\n",
    "                for w in ws:\n",
    "                    w_loc = get_loc(hotspots, w)\n",
    "                    node = Node(name=w, loc=w_loc)\n",
    "                    nodes.append(node)\n",
    "                witnesses[key] = nodes\n",
    "            else:\n",
    "                witnesses[key] = []\n",
    "    return witnesses\n",
    "\n",
    "def create_or_fetch_witness_list(witness_list_pickle):\n",
    "    ''' Check if we already have a pickled object for getting witness list faster '''\n",
    "    if path.exists(witness_list_pickle):\n",
    "        with open(witness_list_pickle, 'rb') as handle:\n",
    "            witness_list = pickle.load(handle)\n",
    "    else:\n",
    "        # make the witness fetching marginally faster by parallelizing requests\n",
    "        witness_list = Parallel(n_jobs=8)(delayed(get_witnesses)(n, a) for (n, a) in [(x['name'], x['address']) for x in hotspots])\n",
    "        with open(witness_list_pickle, 'wb') as handle:\n",
    "            pickle.dump(witness_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return witness_list\n",
    "\n",
    "def create_or_fetch_witness_dict(witness_list, witness_dict_pickle):\n",
    "    ''' Check if we already have a pickled object for getting witness dict faster '''\n",
    "    if path.exists(witness_dict_pickle):\n",
    "        with open(witness_dict_pickle, 'rb') as handle:\n",
    "            witness_dict = pickle.load(handle)\n",
    "    else:\n",
    "        # make the witness fetching marginally faster by parallelizing requests\n",
    "        witness_dict = create_witness_dict(witness_list)\n",
    "        with open(witness_dict_pickle, 'wb') as handle:\n",
    "            pickle.dump(witness_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return witness_dict\n",
    "\n",
    "def create_or_fetch_graph(graph_pickle):\n",
    "    ''' Check if we already have a pickled graph '''\n",
    "    if path.exists(graph_pickle):\n",
    "        return nx.read_gpickle(graph_pickle)\n",
    "    else:\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(witnesses.keys())\n",
    "        for k, v in witnesses.items():\n",
    "            G.add_edges_from([(k, t) for t in v])\n",
    "        nx.write_gpickle(G, graph_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hotspots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr = requests.get(\"{}/hotspots\".format(API))\n",
    "assert(hr.status_code == 200)\n",
    "hotspots = hr.json()['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Witnesses file pickled 3033 hotspots @ height 198410"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if we have witnesses locally\n",
    "witness_list = create_or_fetch_witness_list('files/witnesses.pickle')\n",
    "witnesses = create_or_fetch_witness_dict(witness_list, 'files/witness_dict.pickle')\n",
    "G = create_or_fetch_graph('files/witness_graph.gpickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Is the network connected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.is_connected(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### What is the cluster average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4062333971727669"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nx.algorithms.cluster.average_clustering(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some interesting hotspots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "[Node(loc='8c2830b818889ff', name='proud-clay-aardvark'), Node(loc='8c2830b842235ff', name='short-sky-panther')]\n"
     ]
    }
   ],
   "source": [
    "name='tall-blonde-condor'\n",
    "node = Node(name=name, loc=get_loc(hotspots, name))\n",
    "print(len(nx.node_connected_component(G, node)))\n",
    "print(list(nx.neighbors(G, node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "[Node(loc='8c2830ba0c9a9ff', name='spicy-honey-hawk'), Node(loc='8c283082b00d9ff', name='zealous-cream-swallow'), Node(loc='8c2830ba626d9ff', name='muscular-slate-meerkat'), Node(loc='8c2830ba450b5ff', name='rare-burlap-lizard')]\n"
     ]
    }
   ],
   "source": [
    "name='lone-violet-orca'\n",
    "node = Node(name=name, loc=get_loc(hotspots, name))\n",
    "print(len(nx.node_connected_component(G, node)))\n",
    "print(list(nx.neighbors(G, node)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "[Node(loc='8c283095c768bff', name='sharp-jetblack-dove')]\n"
     ]
    }
   ],
   "source": [
    "name='huge-glossy-robin'\n",
    "node = Node(name=name, loc=get_loc(hotspots, name))\n",
    "print(len(nx.node_connected_component(G, node)))\n",
    "print(list(nx.neighbors(G, node)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many total components? For example: a graph with three compents:\n",
    "<img src=\"files/3-component-graph.png\" style=\"width:400px\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total connected components (sub-graphs): 1222\n"
     ]
    }
   ],
   "source": [
    "cc = list(nx.connected_components(G))\n",
    "scc = sorted(cc, key=len, reverse=True)\n",
    "print('Total connected components (sub-graphs): {}'.format(len(scc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 50 biggest sub graphs: \n",
      "[351, 286, 154, 111, 94, 82, 62, 55, 35, 33, 31, 27, 26, 22, 22, 20, 20, 20, 17, 14, 13, 12, 12, 10, 10, 10, 10, 10, 9, 7, 6, 6, 6, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "print('Top 50 biggest sub graphs: \\n{}'.format([len(i) for i in scc[:50]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
